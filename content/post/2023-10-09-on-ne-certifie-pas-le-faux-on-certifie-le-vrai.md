+++
draft       = false
date        = "2023-10-09"
title       = "On ne certifie pas le faux, on certifie le vrai"
author      = "Pierre Morsa"
categories  = [ "Philosophie de blog" ]
+++

Il y a de nombreux appels aujourd’hui pour forcer les solutions d’intelligence artificielle à mettre en place un système pour reconnaître ce qui a été généré par une IA (intelligence artificielle), que ce soit du texte, des images ou autre chose. À mon sens, créer un système qui vérifie ce qui a été généré par une IA prend le problème est peine perdue, et c’est déjà trop tard ; de nombreuses solutions en circulation libre peuvent s’affranchir des systèmes de contrôle.

Le problème ? Une erreur d’approche. **On ne certifie pas le faux, cela n’a pas de sens. On certifie le vrai.** On ne demande pas aux faussaires de certifier que leurs billets sont faux ; on invente des systèmes pour certifier qu’un billet est vrai. Et c’est la même chose pour les œuvres d’art, la littérature, les photos ou les films. Pour limiter les dégâts de l’intelligence artificielle, il faut une solution qui certifie l’authenticité de l’œuvre.

À mon sens, c’est faisable par les fabricants de smartphones. Par son contrôle matériel et logiciel, Apple pourrait fournir une solution certifiant qu’une photo a bien été prise par un iPhone, résolvant ainsi le problème du « fake ou pas fake ». Tout n’est pas aussi simple. Pour le texte, par exemple, la mise en place d’une solution de certification est bien plus difficile (voire impossible ?). Mais cela vaut la peine de se pencher sur le concept.
